{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all necessary modules \n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "df=pd.read_csv('patient.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HAEMATOCRIT</th>\n",
       "      <th>HAEMOGLOBINS</th>\n",
       "      <th>ERYTHROCYTE</th>\n",
       "      <th>LEUCOCYTE</th>\n",
       "      <th>THROMBOCYTE</th>\n",
       "      <th>MCH</th>\n",
       "      <th>MCHC</th>\n",
       "      <th>MCV</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4.65</td>\n",
       "      <td>6.3</td>\n",
       "      <td>310</td>\n",
       "      <td>25.4</td>\n",
       "      <td>33.6</td>\n",
       "      <td>75.5</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.5</td>\n",
       "      <td>14.8</td>\n",
       "      <td>5.39</td>\n",
       "      <td>12.7</td>\n",
       "      <td>334</td>\n",
       "      <td>27.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>80.7</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.5</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4.74</td>\n",
       "      <td>13.2</td>\n",
       "      <td>305</td>\n",
       "      <td>23.8</td>\n",
       "      <td>33.7</td>\n",
       "      <td>70.7</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.1</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4.98</td>\n",
       "      <td>10.5</td>\n",
       "      <td>366</td>\n",
       "      <td>27.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>78.5</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.9</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4.23</td>\n",
       "      <td>22.1</td>\n",
       "      <td>333</td>\n",
       "      <td>23.4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>out</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HAEMATOCRIT  HAEMOGLOBINS  ERYTHROCYTE  LEUCOCYTE  THROMBOCYTE   MCH  MCHC  \\\n",
       "0         35.1          11.8         4.65        6.3          310  25.4  33.6   \n",
       "1         43.5          14.8         5.39       12.7          334  27.5  34.0   \n",
       "2         33.5          11.3         4.74       13.2          305  23.8  33.7   \n",
       "3         39.1          13.7         4.98       10.5          366  27.5  35.0   \n",
       "4         30.9           9.9         4.23       22.1          333  23.4  32.0   \n",
       "\n",
       "    MCV  AGE SEX SOURCE  \n",
       "0  75.5    1   F    out  \n",
       "1  80.7    1   F    out  \n",
       "2  70.7    1   F    out  \n",
       "3  78.5    1   F    out  \n",
       "4  73.0    1   M    out  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HAEMATOCRIT     0\n",
       "HAEMOGLOBINS    0\n",
       "ERYTHROCYTE     0\n",
       "LEUCOCYTE       0\n",
       "THROMBOCYTE     0\n",
       "MCH             0\n",
       "MCHC            0\n",
       "MCV             0\n",
       "AGE             0\n",
       "SEX             0\n",
       "SOURCE          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HAEMATOCRIT     float64\n",
       "HAEMOGLOBINS    float64\n",
       "ERYTHROCYTE     float64\n",
       "LEUCOCYTE       float64\n",
       "THROMBOCYTE       int64\n",
       "MCH             float64\n",
       "MCHC            float64\n",
       "MCV             float64\n",
       "AGE               int64\n",
       "SEX              object\n",
       "SOURCE           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to apply Label encoder to 'sex','source' column to convert them from object type to integer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SEX']=le.fit_transform(df['SEX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SOURCE']=le.fit_transform(df['SOURCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HAEMATOCRIT</th>\n",
       "      <th>HAEMOGLOBINS</th>\n",
       "      <th>ERYTHROCYTE</th>\n",
       "      <th>LEUCOCYTE</th>\n",
       "      <th>THROMBOCYTE</th>\n",
       "      <th>MCH</th>\n",
       "      <th>MCHC</th>\n",
       "      <th>MCV</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4.65</td>\n",
       "      <td>6.3</td>\n",
       "      <td>310</td>\n",
       "      <td>25.4</td>\n",
       "      <td>33.6</td>\n",
       "      <td>75.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.5</td>\n",
       "      <td>14.8</td>\n",
       "      <td>5.39</td>\n",
       "      <td>12.7</td>\n",
       "      <td>334</td>\n",
       "      <td>27.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>80.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.5</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4.74</td>\n",
       "      <td>13.2</td>\n",
       "      <td>305</td>\n",
       "      <td>23.8</td>\n",
       "      <td>33.7</td>\n",
       "      <td>70.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.1</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4.98</td>\n",
       "      <td>10.5</td>\n",
       "      <td>366</td>\n",
       "      <td>27.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>78.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.9</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4.23</td>\n",
       "      <td>22.1</td>\n",
       "      <td>333</td>\n",
       "      <td>23.4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HAEMATOCRIT  HAEMOGLOBINS  ERYTHROCYTE  LEUCOCYTE  THROMBOCYTE   MCH  MCHC  \\\n",
       "0         35.1          11.8         4.65        6.3          310  25.4  33.6   \n",
       "1         43.5          14.8         5.39       12.7          334  27.5  34.0   \n",
       "2         33.5          11.3         4.74       13.2          305  23.8  33.7   \n",
       "3         39.1          13.7         4.98       10.5          366  27.5  35.0   \n",
       "4         30.9           9.9         4.23       22.1          333  23.4  32.0   \n",
       "\n",
       "    MCV  AGE  SEX  SOURCE  \n",
       "0  75.5    1    0       1  \n",
       "1  80.7    1    0       1  \n",
       "2  70.7    1    0       1  \n",
       "3  78.5    1    0       1  \n",
       "4  73.0    1    1       1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select input and output variable\n",
    "x=df.drop('SOURCE',axis=1) #input variable\n",
    "y=df['SOURCE'] #output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spit data into 2 parts ie. trianing(70%) and testing(30%)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply scalling on input data\n",
    "#import standard scaller\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=StandardScaler()\n",
    "x_train=ss.fit_transform(x_train)#converting into numpy array\n",
    "x_test=ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1834\n",
       "0    1254\n",
       "Name: SOURCE, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check wheather the data is balance or not\n",
    "# first check ytrain(0 and 1) :how many sample of o's and 1's\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#difference is less than 50%\n",
    "#hence no need to apply sampling technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model to perform ML algorithms\n",
    "def create_model(model):\n",
    "    model.fit(x_train,y_train)# train model with 70% data\n",
    "    y_pred=model.predict(x_test)#test with 30% data\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    return model\n",
    "#import classification_report,confusion_matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import logistic regression module\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.53      0.60       530\n",
      "           1       0.73      0.83      0.78       794\n",
      "\n",
      "    accuracy                           0.71      1324\n",
      "   macro avg       0.70      0.68      0.69      1324\n",
      "weighted avg       0.71      0.71      0.70      1324\n",
      "\n",
      "[[283 247]\n",
      " [135 659]]\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(random_state=1)\n",
    "lr=create_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with Logistic Regression we are got f1 score 0=60% 1=78%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Decision Tree Clasifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gini-index method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create meodel using DecisionTree Classifier\n",
    "#import logistic regression module\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.59      0.58       530\n",
      "           1       0.72      0.70      0.71       794\n",
      "\n",
      "    accuracy                           0.66      1324\n",
      "   macro avg       0.65      0.65      0.65      1324\n",
      "weighted avg       0.66      0.66      0.66      1324\n",
      "\n",
      "[[315 215]\n",
      " [238 556]]\n"
     ]
    }
   ],
   "source": [
    "dt=DecisionTreeClassifier(random_state=1)\n",
    "dt=create_model(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with decision tree we got f1 score of 0=58% & 1=71%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THROMBOCYTE</td>\n",
       "      <td>0.243162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAEMATOCRIT</td>\n",
       "      <td>0.151713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LEUCOCYTE</td>\n",
       "      <td>0.135892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.106988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ERYTHROCYTE</td>\n",
       "      <td>0.086722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MCH</td>\n",
       "      <td>0.074010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MCHC</td>\n",
       "      <td>0.071259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MCV</td>\n",
       "      <td>0.068496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HAEMOGLOBINS</td>\n",
       "      <td>0.046866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SEX</td>\n",
       "      <td>0.014891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Input        IG\n",
       "0   THROMBOCYTE  0.243162\n",
       "1   HAEMATOCRIT  0.151713\n",
       "2     LEUCOCYTE  0.135892\n",
       "3           AGE  0.106988\n",
       "4   ERYTHROCYTE  0.086722\n",
       "5           MCH  0.074010\n",
       "6          MCHC  0.071259\n",
       "7           MCV  0.068496\n",
       "8  HAEMOGLOBINS  0.046866\n",
       "9           SEX  0.014891"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check information gain : \n",
    "dict={'Input':x.columns,'IG':dt.feature_importances_} \n",
    "df1=pd.DataFrame(dict)\n",
    "#sorting in decending order \n",
    "df1.sort_values('IG',ascending=False ,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to improve our f1score we apply puring technique\n",
    "#1)max_depth technique\n",
    "#2)min_samples_leaf technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range(1,9):\\n    dt1=DecisionTreeClassifier(random_state=1,max_depth=i)\\n    print('max_depth:',i)\\n    dt1=create_model(dt1)\\n#heat and trial method\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using max_depth technique\n",
    "'''for i in range(1,9):\n",
    "    dt1=DecisionTreeClassifier(random_state=1,max_depth=i)\n",
    "    print('max_depth:',i)\n",
    "    dt1=create_model(dt1)\n",
    "#heat and trial method'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61       530\n",
      "           1       0.74      0.78      0.76       794\n",
      "\n",
      "    accuracy                           0.70      1324\n",
      "   macro avg       0.69      0.68      0.68      1324\n",
      "weighted avg       0.70      0.70      0.70      1324\n",
      "\n",
      "[[310 220]\n",
      " [177 617]]\n"
     ]
    }
   ],
   "source": [
    "dt=DecisionTreeClassifier(random_state=1,max_depth=8)\n",
    "dt=create_model(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with max depth technique we are got f1 score 0=61% 1=76%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range(45,101,1): #i=45 i=47,.....\\n dt2=DecisionTreeClassifier(random_state=1,min_samples_leaf=i)\\n #by default gini index\\n print('min_samples_leaf :',i)\\n #call function\\n dt2=create_model(dt2)\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#second puring technique: min_sampleleaf\n",
    "#min_samples_leaf >=45 and<=100\n",
    "'''for i in range(45,101,1): #i=45 i=47,.....\n",
    " dt2=DecisionTreeClassifier(random_state=1,min_samples_leaf=i)\n",
    " #by default gini index\n",
    " print('min_samples_leaf :',i)\n",
    " #call function\n",
    " dt2=create_model(dt2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61       530\n",
      "           1       0.74      0.82      0.78       794\n",
      "\n",
      "    accuracy                           0.72      1324\n",
      "   macro avg       0.70      0.69      0.69      1324\n",
      "weighted avg       0.71      0.72      0.71      1324\n",
      "\n",
      "[[296 234]\n",
      " [143 651]]\n"
     ]
    }
   ],
   "source": [
    "dt2=DecisionTreeClassifier(random_state=1,min_samples_leaf=98)\n",
    "dt2=create_model(dt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with min_samples_leaf technique we got f1 score 0=61% 1=78%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.62      0.60       530\n",
      "           1       0.73      0.69      0.71       794\n",
      "\n",
      "    accuracy                           0.67      1324\n",
      "   macro avg       0.65      0.66      0.66      1324\n",
      "weighted avg       0.67      0.67      0.67      1324\n",
      "\n",
      "[[330 200]\n",
      " [243 551]]\n"
     ]
    }
   ],
   "source": [
    "dte=DecisionTreeClassifier(random_state=1,criterion='entropy')\n",
    "dte=create_model(dte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we got f1 score of 0=60% & 1=71%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to improve our f1score we apply puring technique\n",
    "#1)max_depth technique\n",
    "#2)min_samples_leaf technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range(1,9):\\n    dte1=DecisionTreeClassifier(random_state=1,max_depth=i,criterion='entropy')\\n    print('max_depth:',i)\\n    dte1=create_model(dte1)\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in range(1,9):\n",
    "    dte1=DecisionTreeClassifier(random_state=1,max_depth=i,criterion='entropy')\n",
    "    print('max_depth:',i)\n",
    "    dte1=create_model(dte1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.54      0.61       530\n",
      "           1       0.73      0.83      0.78       794\n",
      "\n",
      "    accuracy                           0.72      1324\n",
      "   macro avg       0.71      0.69      0.69      1324\n",
      "weighted avg       0.71      0.72      0.71      1324\n",
      "\n",
      "[[288 242]\n",
      " [132 662]]\n"
     ]
    }
   ],
   "source": [
    "dte1=DecisionTreeClassifier(random_state=1,max_depth=5,criterion='entropy')\n",
    "dte1=create_model(dte1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with max depth technique we are got drop in f1 score 0=61% 1=78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range(45,101,1): #i=45 i=47,.....\\n dte2=DecisionTreeClassifier(random_state=1,min_samples_leaf=i,criterion='entropy')\\n #by default gini index\\n print('min_samples_leaf :',i)\\n #call function\\n dte2=create_model(dte2)\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#second puring technique: min_sampleleaf\n",
    "#min_samples_leaf >=45 and<=100\n",
    "'''for i in range(45,101,1): #i=45 i=47,.....\n",
    " dte2=DecisionTreeClassifier(random_state=1,min_samples_leaf=i,criterion='entropy')\n",
    " #by default gini index\n",
    " print('min_samples_leaf :',i)\n",
    " #call function\n",
    " dte2=create_model(dte2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.63       530\n",
      "           1       0.75      0.79      0.77       794\n",
      "\n",
      "    accuracy                           0.71      1324\n",
      "   macro avg       0.70      0.69      0.70      1324\n",
      "weighted avg       0.71      0.71      0.71      1324\n",
      "\n",
      "[[320 210]\n",
      " [170 624]]\n"
     ]
    }
   ],
   "source": [
    "dte2=DecisionTreeClassifier(random_state=1,min_samples_leaf=45,criterion='entropy')\n",
    "dte2=create_model(dte2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crate model using Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'for i in range(10,101):\\n    rfc=RandomForestClassifier(n_estimators=i,random_state=1)\\n    print('no. of decision tree:',i)\\n    rfc=create_model(rfc)\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''for i in range(10,101):\n",
    "    rfc=RandomForestClassifier(n_estimators=i,random_state=1)\n",
    "    print('no. of decision tree:',i)\n",
    "    rfc=create_model(rfc)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.66       530\n",
      "           1       0.77      0.82      0.79       794\n",
      "\n",
      "    accuracy                           0.74      1324\n",
      "   macro avg       0.73      0.72      0.73      1324\n",
      "weighted avg       0.74      0.74      0.74      1324\n",
      "\n",
      "[[333 197]\n",
      " [144 650]]\n"
     ]
    }
   ],
   "source": [
    "#we choose no_decisiontree=25(n_estimator)\n",
    "rfc=RandomForestClassifier(random_state=1,n_estimators=25)\n",
    "rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with Random Forest we got f1 score of 0=66% and 1=79%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THROMBOCYTE</td>\n",
       "      <td>0.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LEUCOCYTE</td>\n",
       "      <td>0.120298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAEMATOCRIT</td>\n",
       "      <td>0.117978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ERYTHROCYTE</td>\n",
       "      <td>0.108363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.094434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HAEMOGLOBINS</td>\n",
       "      <td>0.088600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MCV</td>\n",
       "      <td>0.080516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MCHC</td>\n",
       "      <td>0.076897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MCH</td>\n",
       "      <td>0.072695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SEX</td>\n",
       "      <td>0.017120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Input        IG\n",
       "0   THROMBOCYTE  0.223100\n",
       "1     LEUCOCYTE  0.120298\n",
       "2   HAEMATOCRIT  0.117978\n",
       "3   ERYTHROCYTE  0.108363\n",
       "4           AGE  0.094434\n",
       "5  HAEMOGLOBINS  0.088600\n",
       "6           MCV  0.080516\n",
       "7          MCHC  0.076897\n",
       "8           MCH  0.072695\n",
       "9           SEX  0.017120"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check information gain : \n",
    "dict={'Input':x.columns,'IG':rfc.feature_importances_} \n",
    "df1=pd.DataFrame(dict)\n",
    "#sorting in decending order \n",
    "df1.sort_values('IG',ascending=False ,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range (1,9):\\n     rfc1=RandomForestClassifier(n_estimators=25,random_state=1,max_depth=i)\\n     print('max depth',i)\\n     rfc1=create_model(rfc1)\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply pruning technique 1:max_depth method\n",
    "'''for i in range (1,9):\n",
    "     rfc1=RandomForestClassifier(n_estimators=25,random_state=1,max_depth=i)\n",
    "     print('max depth',i)\n",
    "     rfc1=create_model(rfc1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.59      0.63       530\n",
      "           1       0.75      0.82      0.78       794\n",
      "\n",
      "    accuracy                           0.73      1324\n",
      "   macro avg       0.72      0.71      0.71      1324\n",
      "weighted avg       0.72      0.73      0.72      1324\n",
      "\n",
      "[[313 217]\n",
      " [143 651]]\n"
     ]
    }
   ],
   "source": [
    "rfc1=RandomForestClassifier(n_estimators=25,random_state=1,max_depth=8)\n",
    "rfc1=create_model(rfc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we got f1 score of 0=63% and 1=78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range (45,100):\\n     rfc2=RandomForestClassifier(n_estimators=25,random_state=1,min_samples_leaf=i)\\n     print('minsampeles_leaf',i)\\n     rfc2=create_model(rfc2)\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply second pruning technique ie. min_sample_leaf(>=45 and<=100)\n",
    "'''for i in range (45,100):\n",
    "     rfc2=RandomForestClassifier(n_estimators=25,random_state=1,min_samples_leaf=i)\n",
    "     print('minsampeles_leaf',i)\n",
    "     rfc2=create_model(rfc2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.63       530\n",
      "           1       0.75      0.79      0.77       794\n",
      "\n",
      "    accuracy                           0.71      1324\n",
      "   macro avg       0.70      0.70      0.70      1324\n",
      "weighted avg       0.71      0.71      0.71      1324\n",
      "\n",
      "[[318 212]\n",
      " [166 628]]\n"
     ]
    }
   ],
   "source": [
    "rfc2=RandomForestClassifier(n_estimators=25,random_state=1,min_samples_leaf=49)\n",
    "rfc2=create_model(rfc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we got f1 score of 0=63% and 1=77%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Adaboost Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model using Adaboosting technique\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range(1,11):#as we have 10 input varaiables\\n    ada=AdaBoostClassifier(n_estimators=i,random_state=1)\\n    print('no. of decions stump',i)\\n    ada=create_model(ada)\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in range(1,11):#as we have 10 input varaiables\n",
    "    ada=AdaBoostClassifier(n_estimators=i,random_state=1)\n",
    "    print('no. of decions stump',i)\n",
    "    ada=create_model(ada)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.58      0.63       530\n",
      "           1       0.75      0.83      0.78       794\n",
      "\n",
      "    accuracy                           0.73      1324\n",
      "   macro avg       0.72      0.70      0.71      1324\n",
      "weighted avg       0.72      0.73      0.72      1324\n",
      "\n",
      "[[307 223]\n",
      " [138 656]]\n"
     ]
    }
   ],
   "source": [
    "ada=AdaBoostClassifier(n_estimators=10,random_state=1)\n",
    "ada=create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with Adaboost we got f1 score of  0=63% and 1=78%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import  GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range(10,101):\\n    #create the object of gradientboostclassier class\\n    gbc= GradientBoostingClassifier(n_estimators=i,random_state=1)\\n    print('No of estimators :',i)\\n    #call function\\n    gbc=create_model(gbc)\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in range(10,101):\n",
    "    #create the object of gradientboostclassier class\n",
    "    gbc= GradientBoostingClassifier(n_estimators=i,random_state=1)\n",
    "    print('No of estimators :',i)\n",
    "    #call function\n",
    "    gbc=create_model(gbc)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.66       530\n",
      "           1       0.76      0.82      0.79       794\n",
      "\n",
      "    accuracy                           0.74      1324\n",
      "   macro avg       0.73      0.72      0.72      1324\n",
      "weighted avg       0.74      0.74      0.74      1324\n",
      "\n",
      "[[326 204]\n",
      " [139 655]]\n"
     ]
    }
   ],
   "source": [
    "gbc= GradientBoostingClassifier(n_estimators=65,random_state=1)\n",
    "gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with gradient boosting we got f1 score of 0=66% and 1=79%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using xtreame gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range(10,101):\\n #create the object of XGBclassier class\\n xgc= XGBClassifier(n_estimators=i,random_state=1,reg_alpha=1)\\n print('No of estimators :',i)\\n #call function\\n xgc=create_model(gbc)\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "'''for i in range(10,101):\n",
    " #create the object of XGBclassier class\n",
    " xgc= XGBClassifier(n_estimators=i,random_state=1,reg_alpha=1)\n",
    " print('No of estimators :',i)\n",
    " #call function\n",
    " xgc=create_model(gbc)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shivraj\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:54:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.60      0.65       530\n",
      "           1       0.76      0.82      0.79       794\n",
      "\n",
      "    accuracy                           0.74      1324\n",
      "   macro avg       0.73      0.71      0.72      1324\n",
      "weighted avg       0.73      0.74      0.73      1324\n",
      "\n",
      "[[320 210]\n",
      " [139 655]]\n"
     ]
    }
   ],
   "source": [
    "xgc= XGBClassifier(n_estimators=10,random_state=1,reg_alpha=1)\n",
    "xgc=create_model(xgc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using xtreame boosting we got f1 score of 0=65% and 1=79%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using KNN method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#create object of KNeighnors classifier\n",
    "knc=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "#p=2 means Eucidean distance method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64       530\n",
      "           1       0.76      0.80      0.78       794\n",
      "\n",
      "    accuracy                           0.73      1324\n",
      "   macro avg       0.71      0.71      0.71      1324\n",
      "weighted avg       0.72      0.73      0.72      1324\n",
      "\n",
      "[[328 202]\n",
      " [161 633]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "knc=create_model(knc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using KNN we got f1 score of 0=64% and 1=78%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SVM algorithum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.51      0.58       530\n",
      "           1       0.72      0.84      0.77       794\n",
      "\n",
      "    accuracy                           0.70      1324\n",
      "   macro avg       0.70      0.67      0.67      1324\n",
      "weighted avg       0.70      0.70      0.69      1324\n",
      "\n",
      "[[268 262]\n",
      " [130 664]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shivraj\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "# Create object of linearSVM class\n",
    "svc= LinearSVC(random_state=1)\n",
    "# we have not added any error for our outliers so we will get a line which will be called hard line\n",
    "# we call the function:\n",
    "svc = create_model(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.51      0.58       530\n",
      "           1       0.72      0.84      0.77       794\n",
      "\n",
      "    accuracy                           0.70      1324\n",
      "   macro avg       0.70      0.67      0.67      1324\n",
      "weighted avg       0.70      0.70      0.69      1324\n",
      "\n",
      "[[268 262]\n",
      " [130 664]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shivraj\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#suppose outlier in our dataset means model is overfitted   \n",
    "#so reduce overfit column or remove outlier by adding eternal erro at training time\n",
    "#means again create object of class of  svc and pass charecter 'C' means error\n",
    "# the value of c can be <=1\n",
    "svc1=LinearSVC(random_state=1,C=0.9)# soft margine\n",
    "svc1=create_model(svc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even after changing value of 'c' we got same output \n",
    "#hence it is non linear dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.49      0.58       530\n",
      "           1       0.72      0.86      0.78       794\n",
      "\n",
      "    accuracy                           0.71      1324\n",
      "   macro avg       0.71      0.67      0.68      1324\n",
      "weighted avg       0.71      0.71      0.70      1324\n",
      "\n",
      "[[258 272]\n",
      " [109 685]]\n"
     ]
    }
   ],
   "source": [
    "#polynomial kernal function\n",
    "from sklearn.svm import SVC\n",
    "poly_svc=SVC(random_state=1,kernel='poly')\n",
    "poly_svc=create_model(poly_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.58      0.65       530\n",
      "           1       0.75      0.86      0.80       794\n",
      "\n",
      "    accuracy                           0.75      1324\n",
      "   macro avg       0.74      0.72      0.72      1324\n",
      "weighted avg       0.74      0.75      0.74      1324\n",
      "\n",
      "[[307 223]\n",
      " [113 681]]\n"
     ]
    }
   ],
   "source": [
    "#using radial function\n",
    "radial_svc=SVC(random_state=1,kernel='rbf')\n",
    "radial_svc=create_model(radial_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using SVM(radial svc) we got f1 score of 0=65% and 1=80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Naive Bayes Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.51      0.56       530\n",
      "           1       0.71      0.80      0.75       794\n",
      "\n",
      "    accuracy                           0.68      1324\n",
      "   macro avg       0.67      0.65      0.66      1324\n",
      "weighted avg       0.68      0.68      0.68      1324\n",
      "\n",
      "[[269 261]\n",
      " [157 637]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Creating the object of Gaussian Class\n",
    "gnb = GaussianNB()\n",
    "# Calling the function\n",
    "gnb = create_model(gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with naive bayes we got  f1 score of 0=88% and 1=84%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "We found that for this dataset SVM(Radial SVC) algo gives best f1 score ie 0=65% 1=80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
